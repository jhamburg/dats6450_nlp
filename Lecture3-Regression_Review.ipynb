{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression review "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"training_linear_models\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression using the Normal Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x252cd5bfd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X, y, \"b.\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.axis([0, 2, 0, 15])\n",
    "# save_fig(\"generated_data_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression using batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-85935d2a3331>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mm\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX_b\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_b\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0meta\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_b' is not defined"
     ]
    }
   ],
   "source": [
    "eta = 0.1\n",
    "n_iterations = 1000\n",
    "m = 100\n",
    "theta = np.random.randn(2,1)\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "    theta = theta - eta * gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_b.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_path_bgd = []\n",
    "\n",
    "def plot_gradient_descent(theta, eta, theta_path=None):\n",
    "    m = len(X_b)\n",
    "    plt.plot(X, y, \"b.\")\n",
    "    n_iterations = 1000\n",
    "    for iteration in range(n_iterations):\n",
    "        if iteration < 10:\n",
    "            y_predict = X_new_b.dot(theta)\n",
    "            style = \"b-\" if iteration > 0 else \"r--\"\n",
    "            plt.plot(X_new, y_predict, style)\n",
    "        gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "        theta = theta - eta * gradients\n",
    "        if theta_path is not None:\n",
    "            theta_path.append(theta)\n",
    "    plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "    plt.axis([0, 2, 0, 15])\n",
    "    plt.title(r\"$\\eta = {}$\".format(eta), fontsize=16)\n",
    "\n",
    "np.random.seed(42)\n",
    "theta = np.random.randn(2,1)  # random initialization\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(131); plot_gradient_descent(theta, eta=0.02)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.subplot(132); plot_gradient_descent(theta, eta=0.1, theta_path=theta_path_bgd)\n",
    "plt.subplot(133); plot_gradient_descent(theta, eta=0.5)\n",
    "\n",
    "save_fig(\"gradient_descent_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "theta = np.random.randn(2,1)  # random initialization\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(131); plot_gradient_descent(theta, eta=0.02)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.subplot(132); plot_gradient_descent(theta, eta=0.1, theta_path=theta_path_bgd)\n",
    "plt.subplot(133); plot_gradient_descent(theta, eta=0.5)\n",
    "\n",
    "save_fig(\"gradient_descent_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_path_sgd = []\n",
    "m = len(X_b)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "t0, t1 = 5, 50  # learning schedule hyperparameters\n",
    "\n",
    "def learning_schedule(t):\n",
    "    return t0 / (t + t1)\n",
    "\n",
    "theta = np.random.randn(2,1)  # random initialization\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(m):\n",
    "        if epoch == 0 and i < 20:                    # not shown in the book\n",
    "            y_predict = X_new_b.dot(theta)           # not shown\n",
    "            style = \"b-\" if i > 0 else \"r--\"         # not shown\n",
    "            plt.plot(X_new, y_predict, style)        # not shown\n",
    "        random_index = np.random.randint(m)\n",
    "        xi = X_b[random_index:random_index+1]\n",
    "        yi = y[random_index:random_index+1]\n",
    "        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
    "        eta = learning_schedule(epoch * m + i)\n",
    "        theta = theta - eta * gradients\n",
    "        theta_path_sgd.append(theta)                 # not shown\n",
    "\n",
    "plt.plot(X, y, \"b.\")                                 # not shown\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)                     # not shown\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)           # not shown\n",
    "plt.axis([0, 2, 0, 15])                              # not shown\n",
    "save_fig(\"sgd_plot\")                                 # not shown\n",
    "plt.show()                                           # not shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_reg = SGDRegressor(n_iter=50, penalty=None, eta0=0.1, random_state=42)\n",
    "sgd_reg.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg.intercept_, sgd_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_path_mgd = []\n",
    "\n",
    "n_iterations = 50\n",
    "minibatch_size = 20\n",
    "\n",
    "np.random.seed(42)\n",
    "theta = np.random.randn(2,1)  # random initialization\n",
    "\n",
    "t0, t1 = 10, 1000\n",
    "def learning_schedule(t):\n",
    "    return t0 / (t + t1)\n",
    "\n",
    "t = 0\n",
    "for epoch in range(n_iterations):\n",
    "    shuffled_indices = np.random.permutation(m)\n",
    "    X_b_shuffled = X_b[shuffled_indices]\n",
    "    y_shuffled = y[shuffled_indices]\n",
    "    for i in range(0, m, minibatch_size):\n",
    "        t += 1\n",
    "        xi = X_b_shuffled[i:i+minibatch_size]\n",
    "        yi = y_shuffled[i:i+minibatch_size]\n",
    "        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
    "        eta = learning_schedule(t)\n",
    "        theta = theta - eta * gradients\n",
    "        theta_path_mgd.append(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_path_bgd = np.array(theta_path_bgd)\n",
    "theta_path_sgd = np.array(theta_path_sgd)\n",
    "theta_path_mgd = np.array(theta_path_mgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(theta_path_sgd[:, 0], theta_path_sgd[:, 1], \"r-s\", linewidth=1, label=\"Stochastic\")\n",
    "plt.plot(theta_path_mgd[:, 0], theta_path_mgd[:, 1], \"g-+\", linewidth=2, label=\"Mini-batch\")\n",
    "plt.plot(theta_path_bgd[:, 0], theta_path_bgd[:, 1], \"b-o\", linewidth=3, label=\"Batch\")\n",
    "plt.legend(loc=\"upper left\", fontsize=16)\n",
    "plt.xlabel(r\"$\\theta_0$\", fontsize=20)\n",
    "plt.ylabel(r\"$\\theta_1$   \", fontsize=20, rotation=0)\n",
    "plt.axis([2.5, 4.5, 2.3, 3.9])\n",
    "save_fig(\"gradient_descent_paths_plot\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
